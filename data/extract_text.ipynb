{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from rapidfuzz import process\n",
    "from rapidfuzz import fuzz\n",
    "from glob import glob\n",
    "import warnings\n",
    "from bs4 import XMLParsedAsHTMLWarning\n",
    "warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
    "filepath  = \"export_job_15918348/**/*.xml\" \n",
    "files = glob(filepath, recursive=True)\n",
    "import time\n",
    "import numpy as np\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-13T13:30:12.669803700Z",
     "start_time": "2025-08-13T13:30:12.533891600Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# files = [file for file in files if file.split('\\\\')[-1].replace('.xml','') in [\"PlakkaatboekDeel03\", \"PlakkaatboekDeel04\", \"PlakkaatboekDeel13\", \"PlakkaatboekDeel14\"]]\n",
    "\n",
    "# 16 ver and 15 ver uses articles, 15th uses old month names "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-13T13:30:12.721113900Z",
     "start_time": "2025-08-13T13:30:12.553374800Z"
    }
   },
   "id": "bd9de4e1493ed4f9"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "maanden = [\n",
    "    \"louwmaand\", \"sprokkelmaand\", \"lentmaand\", \"grasmaand\", \"blooimand\", \"zomermaand\", \n",
    "    \"hooimaand\", \"oogstmaand\", \"herfstmaand\", \"wijnmaand\", \"slaghtmaand\", \"wintermaand\",\n",
    "    \"januari\", \"februari\", \"maart\", \"april\", \"mei\", \"juni\",\n",
    "    \"juli\", \"augustus\", \"september\", \"oktober\", \"november\", \"december\",\n",
    "    \"Januari\", \"Februari\", \"Maart\", \"April\", \"Mei\", \"Juni\",\n",
    "    \"Juli\", \"Augustus\", \"September\", \"Oktober\", \"November\", \"December\",\n",
    "    'Louwmaand', 'Sprokkelmaand', 'Lentmaand', 'Grasmaand', 'Blooimand', 'Zomermaand',\n",
    "    'Hooimaand', 'Oogstmaand', 'Herfstmaand', 'Wijnmaand', 'Slaghtmaand', 'Wintermaand'\n",
    "]\n",
    "\n",
    "def fuzzy_matching(word, threshold=80):\n",
    "    match1, score1, _ = process.extractOne(word, maanden, scorer=fuzz.ratio)\n",
    "    return score1 >= threshold and len(word) >= 3\n",
    "\n",
    "def fuzzy_matching_google(word, threshold=70):\n",
    "        match, score, _ = process.extractOne(word, ['Digitized by Google'])\n",
    "        return score >= threshold or \"google\" in word.lower()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-13T13:30:12.721113900Z",
     "start_time": "2025-08-13T13:30:12.572608900Z"
    }
   },
   "id": "11582443063cb57"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "13"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i) for i in maanden])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-13T13:30:12.721113900Z",
     "start_time": "2025-08-13T13:30:12.585104200Z"
    }
   },
   "id": "a47ac881f9f144af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GET LINES"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2febcba1dfd9897"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def format_lines(test_df):\n",
    "    bool_has_year = []\n",
    "    bool_has_date = []\n",
    "    bool_has_google = []\n",
    "    for x in test_df['line']:\n",
    "        splits = x.split('.')\n",
    "        # split at either first number or first space: need to find month\n",
    "        dates = list(filter(None, re.split('(\\d{1,})|\\s', splits[0])))\n",
    "        # print(dates)\n",
    "    \n",
    "        if 0 < len(dates):\n",
    "            # print(dates[-1], fuzzy_matching(dates[-1]))\n",
    "            if fuzzy_matching(dates[-1]): # To do when merging check if random dates arent picked up.\n",
    "                bool_has_date.append(True)          # if date then no year\n",
    "                bool_has_year.append(False)\n",
    "            else:\n",
    "                bool_has_date.append(False)         # if no date then check for year\n",
    "                bool_has_year.append(dates[0].isdigit() and len(dates[0])==4)\n",
    "        else:\n",
    "            bool_has_year.append(False)             # otherwise just text\n",
    "            bool_has_date.append(False)\n",
    "        \n",
    "        bool_has_google.append(fuzzy_matching_google(x))\n",
    "        \n",
    "    test_df['boolHasLegisDate'] = bool_has_date\n",
    "    test_df['boolHasLegisYear'] = bool_has_year\n",
    "    test_df['boolHasGoogle'] = bool_has_google\n",
    "    test_df = test_df[test_df['boolHasGoogle']==False]\n",
    "    return test_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-13T13:30:12.721113900Z",
     "start_time": "2025-08-13T13:30:12.594404400Z"
    }
   },
   "id": "8604088852bdc1f1"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On xml: PlakkaatboekDeel03\n",
      "     Time: 0.9115850925445557\n",
      "On xml: PlakkaatboekDeel01\n",
      "     Time: 1.3408699035644531\n",
      "On xml: PlakkaatboekDeel02\n",
      "     Time: 0.8468208312988281\n",
      "On xml: PlakkaatboekDeel05\n",
      "     Time: 1.0240871906280518\n",
      "On xml: PlakkaatboekDeel17\n",
      "     Time: 1.505370855331421\n",
      "On xml: PlakkaatboekDeel16\n",
      "     Time: 1.0571069717407227\n",
      "On xml: PlakkaatboekDeel15\n",
      "     Time: 1.5350995063781738\n",
      "On xml: PlakkaatboekDeel09\n",
      "     Time: 0.8653302192687988\n",
      "On xml: PlakkaatboekDeel04\n",
      "     Time: 1.2274816036224365\n",
      "On xml: PlakkaatboekDeel14\n",
      "     Time: 1.1546740531921387\n",
      "On xml: PlakkaatboekDeel06\n",
      "     Time: 1.1519150733947754\n",
      "On xml: PlakkaatboekDeel08\n",
      "     Time: 1.321084976196289\n",
      "On xml: PlakkaatboekDeel13\n",
      "     Time: 1.029449701309204\n",
      "On xml: PlakkaatboekDeel11\n",
      "     Time: 1.1968235969543457\n",
      "On xml: PlakkaatboekDeel07\n",
      "     Time: 1.1547691822052002\n",
      "On xml: PlakkaatboekDeel10\n",
      "     Time: 1.3759105205535889\n",
      "On xml: PlakkaatboekDeel12\n",
      "     Time: 1.476513385772705\n"
     ]
    }
   ],
   "source": [
    "# first get all features\n",
    "for file in files:\n",
    "\n",
    "    df = None\n",
    "\n",
    "    with open(file, encoding='UTF-8') as fp:\n",
    "        soup = BeautifulSoup(fp, 'xml', from_encoding='utf-8')\n",
    "    num_pages = len(soup.find_all(\"pb\"))\n",
    "    filename = file.split('\\\\')[-1].replace('.xml','')\n",
    "    print(f\"On xml: {filename}\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # line wise  \n",
    "    ps = soup.find_all(\"zone\", attrs={\"rendition\": 'Line'})\n",
    "    ids = [\"#\" + y.attrs['xml:id'] for y in ps]\n",
    "    points = [[int(i) for x in y.attrs[\"points\"].split(' ') for i in x.split(',')] for y in ps]\n",
    "    # print(len(points), len(ids))\n",
    "\n",
    "    # first df for points and ids\n",
    "    df1 = pd.DataFrame({\"points\": points, \"id\": ids})\n",
    "\n",
    "    ps = soup.find_all(\"l\")\n",
    "    texts = [x.text for x in ps]\n",
    "    ids = [x.attrs['facs'] for x in ps]\n",
    "    # print(len(texts), len(ids))\n",
    "\n",
    "    # second df for ids and lines\n",
    "    df2 = pd.DataFrame({\"line\": texts, \"id\": ids})\n",
    "\n",
    "    # since id is 1->1 merge on id\n",
    "    df = pd.merge(df1, df2, on='id')\n",
    "    # remove nans and empty strs\n",
    "    df.dropna(inplace=True)\n",
    "    df = df[df['line'].str.strip().astype(bool)]\n",
    "    df = format_lines(df)\n",
    "    end = time.time()\n",
    "    print(f\"     Time: {end-start}\")\n",
    "    df.to_csv(f'raw/placaatboek/csvs/{filename}_lines.csv', encoding=\"utf-8\")    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-13T13:31:28.939926800Z",
     "start_time": "2025-08-13T13:30:12.610474700Z"
    }
   },
   "id": "1c9aa9cbf57ed1d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classifier for detecting year"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3b9353891ff8ebe"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "# import pandas as pd\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-13T13:31:28.959594700Z",
     "start_time": "2025-08-13T13:31:28.937916700Z"
    }
   },
   "id": "9e1496f06cf5b8da"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# test_df= "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-13T13:31:28.974895600Z",
     "start_time": "2025-08-13T13:31:28.951893900Z"
    }
   },
   "id": "6aab0429a6afb1bc"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# remove_coords = pd.DataFrame(test_df[test_df['boolHasLegisYear']==1]['points'])\n",
    "# remove_coords['boolRemove'] = [1]*len(remove_coords)\n",
    "# non_remove_coords = pd.DataFrame(test_df[test_df['boolHasLegisYear']==0].sample(len(remove_coords)*3)['points'])\n",
    "# non_remove_coords['boolRemove'] = [0]*len(non_remove_coords)\n",
    "# classifier_dataset = pd.concat([remove_coords, non_remove_coords])\n",
    "# classifier_dataset = classifier_dataset.sample(frac=1).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-13T13:31:28.985699900Z",
     "start_time": "2025-08-13T13:31:28.971340800Z"
    }
   },
   "id": "4fc374bd43b96ab3"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# classifier_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-13T13:31:29.004427100Z",
     "start_time": "2025-08-13T13:31:28.985699900Z"
    }
   },
   "id": "c071f882d8882348"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# X = pd.DataFrame(classifier_dataset['points'].to_list()).fillna(0)\n",
    "# \n",
    "# y = classifier_dataset['boolRemove'].to_numpy()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# \n",
    "# clf = KNeighborsClassifier(n_neighbors=3)\n",
    "# clf.fit(X_train, y_train)\n",
    "# predictions = clf.predict(X_test)\n",
    "# cm = confusion_matrix(y_test, predictions, labels=clf.classes_, normalize='pred')\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "#                               display_labels=clf.classes_)\n",
    "# disp.plot()\n",
    "# plt.savefig(\"C:/Users/imruh/Documents/date-extraction-dutch-east-indies/data/CM_headingremoval.png\")\n",
    "# pickle.dump(clf, open('C:/Users/imruh/Documents/date-extraction-dutch-east-indies/data/KNN_headingremoval', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-13T13:31:29.022911100Z",
     "start_time": "2025-08-13T13:31:29.004427100Z"
    }
   },
   "id": "cb2d5bc31e545eda"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
